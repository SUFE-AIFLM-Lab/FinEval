# Parameter Configuration Description

## 1. Configuration instructions

The parameter combination of few-shot and cot can produce four evaluation methods:

- few-shot=False and cot=False: means that zero-shot only answers the answer.
- few-shot=True and cot=False: means that few-shot only answers the answer.
- few-shot=False and cot=True: The zero-shot method adopts the CoT method to answer.
- few-shot=True and cot=True: The few-shot method uses the CoT method to answer.

Generally speaking, the effect of the few-shot Base model in the pretraining stage will be better than zero-shot, but the Chat model that has been aligned with human preferences is likely to have a better zero-shot effect than the Base model.

Different model_types represent different model model reading configurations, and model_type can be selected from the following configurations:

```text
"bloom": (BloomForCausalLM, BloomTokenizerFast),
"chatglm": (AutoModel, AutoTokenizer),
"llama": (LlamaForCausalLM, LlamaTokenizer),
"baichuan": (AutoModelForCausalLM, AutoTokenizer),
"auto": (AutoModelForCausalLM, AutoTokenizer),
"moss":(AutoConfig, AutoTokenizer)
```

## 2. Model configuration information

The following is the model configuration information:

```text
--model_type model name
--model_path model path
--cot  Whether to use Chain-of-thought
--few_shot  Whether to use few-shot learning
--with_prompt  Whether to use the prompt template of alpaca, the default is not applicable
--ntrain The number of few-shot, if few-shot is False, this parameter is invalid
--constrained_decoding Whether to use the restricted decoding method, since the evaluation standard answer of fineval is ABCD, two answer schemes extracted from the model are provided: when constrained_decoding=True, calculate the probability that the first token generated by the model is ABCD, and select the probability The largest as an answer; when constrained_decoding=False, use a regular expression to extract the answer from the model-generated content.
--temperature Temperature for model decoding
--n_times Specify the number of repetitions of the evaluation, put the model under output_dir to generate a folder with the specified number of times, the default is 1, and the generated folder is toke0
--do_save_csv Whether to save the model generation results, extracted answers, etc. in the csv file
--do_test Test on the valid and test sets, when do_test=False, test on the valid set; when do_test=True, test on the test set
--gpus The number of gpus used in model testing
--only_cpu True Whether to use only cpu for evaluation
--output_dir Specify the output path of the evaluation results
```

